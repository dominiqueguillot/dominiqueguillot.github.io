
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>14. Lab 5: Coordinate descent &#8212; Math 637 Mathematical Techniques in Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Content/15-Lab5-coordinate-descent';</script>
    <link rel="canonical" href="/637book/Content/15-Lab5-coordinate-descent.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="15. Theoretical guarantees for the LASSO" href="16-LASSO-theoretical.html" />
    <link rel="prev" title="13. Computing the LASSO solution" href="14-Computing-lasso.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="1-intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/637-logo.png" class="logo__image only-light" alt="Math 637 Mathematical Techniques in Data Science - Home"/>
    <script>document.write(`<img src="../_static/637-logo.png" class="logo__image only-dark" alt="Math 637 Mathematical Techniques in Data Science - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="1-intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2-Python.html">1. Setting up Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="3-Basic-Python.html">2. Basic Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="4-Supervised-Unsupervised.html">3. Supervised vs Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-Linear-regression.html">4. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="6-Lab-Cars.html">5. Lab 1: Linear regression and the cars data</a></li>
<li class="toctree-l1"><a class="reference internal" href="7-Learning-outside-training.html">6. Learning outside the training set</a></li>
<li class="toctree-l1"><a class="reference internal" href="8-Lab2-train-test.html">7. Lab 2: Training vs testing error</a></li>
<li class="toctree-l1"><a class="reference internal" href="9-BLUE.html">8. Best linear unbiased estimator and the bias-variance decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-Lab3-gradient-descent.html">9. Lab 3: Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-Shrinkage-methods.html">10. Improving linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-Model-selection.html">11. Model selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-Lab4-lasso.html">12. Lab 4: using the LASSO</a></li>
<li class="toctree-l1"><a class="reference internal" href="14-Computing-lasso.html">13. Computing the LASSO solution</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">14. Lab 5: Coordinate descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="16-LASSO-theoretical.html">15. Theoretical guarantees for the LASSO</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-categorical-data.html">16. Analyzing categorical data</a></li>
<li class="toctree-l1"><a class="reference internal" href="18-Lab6-nearest-neighbors.html">17. Lab 6: nearest neighbors</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Content/15-Lab5-coordinate-descent.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lab 5: Coordinate descent</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-via-coordinate-descent">14.1. Linear regression via coordinate descent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-lasso-problem-using-coordinate-descent">14.2. Solving the LASSO problem using coordinate descent</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lab-5-coordinate-descent">
<h1><span class="section-number">14. </span>Lab 5: Coordinate descent<a class="headerlink" href="#lab-5-coordinate-descent" title="Link to this heading">#</a></h1>
<p>We saw previously how <a class="reference internal" href="14-Computing-lasso.html#s-coordinate-descent"><span class="std std-ref">Coordinate descent</span></a> can be used to minimize a function <span class="math notranslate nohighlight">\(f(x_1,\dots,x_p)\)</span> of several variables. Recall that the idea is to minimize the function one variable at a time, and to repeat this process over and over:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
x^{(k+1)}_1 &amp;= \mathop{\textrm{argmin}}_x f(x, x_2^{(k)}, x_3^{(k)}, \dots, x_p^{(k)}) \\
x^{(k+1)}_2 &amp;= \mathop{\textrm{argmin}}_x f(x_1^{(k+1)}, x, x_3^{(k)}, \dots, x_p^{(k)}) \\
x^{(k+1)}_3 &amp;= \mathop{\textrm{argmin}}_x f(x_1^{(k+1)}, x_2^{(k+1)}, x, x_4^{(k)}, \dots, x_p^{(k)})\\
&amp;\vdots \\
x^{(k+1)}_p &amp;= \mathop{\textrm{argmin}}_x f(x_1^{(k+1)}, x_2^{(k+1)}, \dots , x_{p-1}^{(k+1)}, x).
\end{align*}\]</div>
<p>Under certain conditions, this process converges to a local minimum of the function <span class="math notranslate nohighlight">\(f\)</span>. To illustrate how this work with Python, let us solve the linear regression problem using coordinate descent.</p>
<section id="linear-regression-via-coordinate-descent">
<h2><span class="section-number">14.1. </span>Linear regression via coordinate descent<a class="headerlink" href="#linear-regression-via-coordinate-descent" title="Link to this heading">#</a></h2>
<p>Consider the least square problem</p>
<div class="math notranslate nohighlight">
\[
\min_{\beta \in \mathbb{R}^p} \|y-X\beta\|_2^2, 
\]</div>
<p>where <span class="math notranslate nohighlight">\(y \in \mathbb{R}^n\)</span> and <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n \times p}\)</span> are fixed. In order to solve this problem via coordinate descent, we need to solve the one-variable problem</p>
<div class="math notranslate nohighlight">
\[
\min_{\beta_i \in \mathbb{R}^p} \|y-X\beta\|_2^2.
\]</div>
<p>We will do so by computing the derivative of <span class="math notranslate nohighlight">\(\|y-X\beta\|_2^2\)</span> with respect to <span class="math notranslate nohighlight">\(\beta_i\)</span> and setting it to <span class="math notranslate nohighlight">\(0\)</span>. Recall from <a class="reference internal" href="5-Linear-regression.html#sec-finding-optimal-coefficients"><span class="std std-ref">Finding the Optimal Coefficients</span></a> that</p>
<div class="math notranslate nohighlight">
\[
\nabla_\beta \|y-X\beta\|_2^2 = -2(X^Ty-X^TX \beta) = -2X^T(y-X\beta). 
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\nabla_\beta\)</span> denotes the gradient vector obtained by differentiating with respect to <span class="math notranslate nohighlight">\(\beta_1, \dots, \beta_p\)</span>. In particular, for <span class="math notranslate nohighlight">\(1 \leq i \leq p\)</span>, the <span class="math notranslate nohighlight">\(i\)</span>-th entry of the gradient is:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial}{\partial \beta_i} \|y-X\beta\|_2^2 = -2 X_i^T (y-X\beta), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(X_i\)</span> denotes the <span class="math notranslate nohighlight">\(i\)</span>-th column of <span class="math notranslate nohighlight">\(X\)</span>. Now, let <span class="math notranslate nohighlight">\(X_{-i}\)</span> denote the matrix <span class="math notranslate nohighlight">\(X\)</span> with the <span class="math notranslate nohighlight">\(i\)</span>-th column deleted, and let <span class="math notranslate nohighlight">\(\beta_{-i}\)</span> be the vector <span class="math notranslate nohighlight">\(\beta\)</span> with <span class="math notranslate nohighlight">\(i\)</span>-th entry deleted. Observe that <span class="math notranslate nohighlight">\(X\beta\)</span> = <span class="math notranslate nohighlight">\(X_{-i} \beta_{-i} + \beta_i X_i\)</span>. It follows that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\frac{\partial}{\partial \beta_i} \|y-X\beta\|_2^2 &amp;= -2 X_i^T (y-X_{-i}\beta_{-i} - \beta_i X_i) \\
&amp;= -2(X_i^T y - X_i^T X_{-i} \beta_{-i} - \beta_iX_i^T X_i).
\end{align*}\]</div>
<p>Setting the gradient to <span class="math notranslate nohighlight">\(0\)</span> and solving for <span class="math notranslate nohighlight">\(\beta_i\)</span>, we obtain:</p>
<div class="math notranslate nohighlight">
\[
\beta_i^* = \mathop{\rm argmin}_{\beta_i \in \mathbb{R}} \|y-X\beta\|_2^2 = \frac{X_i^T(y-X_{-i}\beta{-i})}{X_i^T X_i}.
\]</div>
<p>We can therefore solve the linear regression via coordinate descent as follows.</p>
<div class="admonition-linear-regression-coordinate-descent admonition">
<p class="admonition-title">Linear regression - coordinate descent</p>
<p><strong>Input</strong>: <span class="math notranslate nohighlight">\(y \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n \times p}\)</span>, initial guess <span class="math notranslate nohighlight">\(\beta^{(0)}\)</span>, tolerence <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>.</p>
<p>Set <span class="math notranslate nohighlight">\(k = 0\)</span>.</p>
<p>while <span class="math notranslate nohighlight">\(\|\left(\nabla \|y-X\beta^{(k)}\|_2^2\right)\|_2 &gt; \epsilon\)</span>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\beta^{(k+1)} = \beta^{(k)}\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(i=1,\dots,p\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\beta_i^{(k+1)} = \frac{X_i^T(y-X_{-i}\beta{-i}^{(k+1)})}{X_i^T X_i}. 
\]</div>
<ol class="arabic simple" start="3">
<li><p>Set <span class="math notranslate nohighlight">\(k = k+1\)</span>.</p></li>
</ol>
<p><strong>Output</strong>: A vector <span class="math notranslate nohighlight">\(\beta = \beta^{(k)} \in \mathbb{R}^p\)</span> such that <span class="math notranslate nohighlight">\(\|\nabla \left(\|y-X\beta\|_2^2\right)\|_2 \leq \epsilon\)</span>.</p>
</div>
<p>Let us implement this algorithm in Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the norm of the gradient function</span>

<span class="k">def</span> <span class="nf">gradnorm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span>
    <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">,</span> <span class="n">maxit</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
	<span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
	
	<span class="k">if</span> <span class="n">beta0</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># No initial guess was provided. Generate one at random.</span>
		<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">beta</span> <span class="o">=</span> <span class="n">beta0</span>
		
	<span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
	<span class="n">grad</span> <span class="o">=</span> <span class="n">gradnorm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">)</span>
	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iter </span><span class="se">\t</span><span class="s2"> Grad </span><span class="se">\t</span><span class="s2"> Err&quot;</span><span class="p">)</span>
	<span class="k">while</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">maxit</span> <span class="ow">and</span> <span class="n">grad</span> <span class="o">&gt;</span> <span class="n">epsilon</span><span class="p">:</span>
		<span class="n">beta_old</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
			<span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
			<span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1"># ind now contains all indices in {1,...,p} except i.</span>
			<span class="n">Xi</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span>
			<span class="n">Xmi</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">ind</span><span class="p">]</span>  <span class="c1"># All columns of X except the i-th.</span>
			<span class="n">betami</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
			<span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">Xmi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">betami</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">Xi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xi</span><span class="p">))</span>
				
		<span class="n">grad</span> <span class="o">=</span> <span class="n">gradnorm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
		<span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span> <span class="c1"># Evaluates the norm of y-X*beta</span>
		<span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> </span><span class="si">%f</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>
	<span class="k">return</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now test our code using random data and compare its solution with the solution of the problem obtained by Scikit-learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>	
<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
	<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
	<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
	<span class="n">mod</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
	<span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
	<span class="n">beta1</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">coef_</span>
	<span class="n">beta2</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">maxit</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
	<span class="nb">print</span><span class="p">(</span><span class="n">beta1</span><span class="o">-</span><span class="n">beta2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iter 	 Grad 	 Err
1 	 0.954070 	 0.939715
2 	 0.584466 	 0.850417
3 	 0.356145 	 0.814383
4 	 0.215657 	 0.800604
5 	 0.129680 	 0.795509
6 	 0.077469 	 0.793672
7 	 0.046127 	 0.793026
8 	 0.027654 	 0.792805
9 	 0.017075 	 0.792731
10 	 0.011243 	 0.792706
11 	 0.008102 	 0.792697
12 	 0.006322 	 0.792693
13 	 0.005159 	 0.792691
14 	 0.004276 	 0.792689
15 	 0.003544 	 0.792688
16 	 0.002922 	 0.792687
17 	 0.002392 	 0.792687
18 	 0.001945 	 0.792686
19 	 0.001573 	 0.792686
20 	 0.001265 	 0.792686
21 	 0.001014 	 0.792686
22 	 0.000810 	 0.792686
23 	 0.000646 	 0.792685
24 	 0.000514 	 0.792685
25 	 0.000408 	 0.792685
26 	 0.000324 	 0.792685
27 	 0.000256 	 0.792685
28 	 0.000203 	 0.792685
29 	 0.000161 	 0.792685
30 	 0.000127 	 0.792685
31 	 0.000100 	 0.792685
32 	 0.000079 	 0.792685
33 	 0.000063 	 0.792685
34 	 0.000049 	 0.792685
35 	 0.000039 	 0.792685
36 	 0.000031 	 0.792685
37 	 0.000024 	 0.792685
38 	 0.000019 	 0.792685
39 	 0.000015 	 0.792685
40 	 0.000012 	 0.792685
41 	 0.000009 	 0.792685
42 	 0.000007 	 0.792685
43 	 0.000006 	 0.792685
44 	 0.000005 	 0.792685
45 	 0.000004 	 0.792685
46 	 0.000003 	 0.792685
47 	 0.000002 	 0.792685
48 	 0.000002 	 0.792685
49 	 0.000001 	 0.792685
50 	 0.000001 	 0.792685
51 	 0.000001 	 0.792685
[ 2.06896746e-07  5.52669806e-07 -4.93305344e-07]
</pre></div>
</div>
</div>
</div>
<p>We obtain the same regression coefficients (up to numerical precision).</p>
</section>
<section id="solving-the-lasso-problem-using-coordinate-descent">
<h2><span class="section-number">14.2. </span>Solving the LASSO problem using coordinate descent<a class="headerlink" href="#solving-the-lasso-problem-using-coordinate-descent" title="Link to this heading">#</a></h2>
<p>Let us now consider the LASSO problem</p>
<div class="math notranslate nohighlight">
\[
\widehat{\beta}_\textrm{LASSO} = \mathop{\textrm{argmin}}_{\beta \in \mathbb{R}^p} \|y - X\beta\|_2^2 + \alpha \|\beta\|_1.
\]</div>
<p>Recall that the updated derived in <a class="reference internal" href="14-Computing-lasso.html#s-lasso-soln"><span class="std std-ref">Back to the LASSO solution</span></a> is</p>
<div class="math notranslate nohighlight">
\[
\beta_i \rightarrow \eta^S_{\lambda/\|X_i\|_2^2} \left(\frac{2 X_i^T (y-X_{-i} \beta_{-i}) }{X_i^T X_i}\right).
\]</div>
<p>This is almost the same update as in the linear regression problem.</p>
<div class="admonition-exercise admonition">
<p class="admonition-title">Exercise</p>
<p>Modify the above code to solve the LASSO problem instead of linear regression. Compare your solution with Scikit-learn and make sure the two versions match. Note that the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html" target="_blank">Lasso object of Scikit-learn</a> solves a slightly different (but equivalent) LASSO problem</p>
<div class="math notranslate nohighlight">
\[
\min_{w \in \mathbb{R}^p} \frac{1}{2n}  ||y - Xw||^2_2 + \alpha  ||w||_1.
\]</div>
<p>Observe that setting <span class="math notranslate nohighlight">\(\alpha = \frac{\lambda}{2n}\)</span> solves</p>
<div class="math notranslate nohighlight">
\[
\min_{w \in \mathbb{R}^p} \frac{1}{2n} ||y - Xw||^2_2 + \frac{\lambda}{2n}  ||w||_1 = \frac{1}{2n} \min_{w \in \mathbb{R}^p} ||y - Xw||^2_2 + \lambda  ||w||_1, 
\]</div>
<p>which is equivalent to our formulation.</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="14-Computing-lasso.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">13. </span>Computing the LASSO solution</p>
      </div>
    </a>
    <a class="right-next"
       href="16-LASSO-theoretical.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Theoretical guarantees for the LASSO</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-via-coordinate-descent">14.1. Linear regression via coordinate descent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-lasso-problem-using-coordinate-descent">14.2. Solving the LASSO problem using coordinate descent</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dominique Guillot
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>