
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>14. Lab 5: Coordinate descent &#8212; Math 637 Mathematical Techniques in Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Content/15-Lab5-coordinate-descent';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="15. Theoretical guarantees for the LASSO" href="16-LASSO-theoretical.html" />
    <link rel="prev" title="13. Computing the LASSO solution" href="14-Computing-lasso.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="1-intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/637-logo.png" class="logo__image only-light" alt="Math 637 Mathematical Techniques in Data Science - Home"/>
    <script>document.write(`<img src="../_static/637-logo.png" class="logo__image only-dark" alt="Math 637 Mathematical Techniques in Data Science - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="1-intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2-Python.html">1. Setting up Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="3-Basic-Python.html">2. Basic Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="4-Supervised-Unsupervised.html">3. Supervised vs Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-Linear-regression.html">4. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="6-Lab-Cars.html">5. Lab 1: Linear regression and the cars data</a></li>
<li class="toctree-l1"><a class="reference internal" href="7-Learning-outside-training.html">6. Learning outside the training set</a></li>
<li class="toctree-l1"><a class="reference internal" href="8-Lab2-train-test.html">7. Lab 2: Training vs testing error</a></li>
<li class="toctree-l1"><a class="reference internal" href="9-BLUE.html">8. Best linear unbiased estimator and the bias-variance decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-Lab3-gradient-descent.html">9. Lab 3: Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-Shrinkage-methods.html">10. Improving linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-Model-selection.html">11. Model selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-Lab4-lasso.html">12. Lab 4: using the LASSO</a></li>
<li class="toctree-l1"><a class="reference internal" href="14-Computing-lasso.html">13. Computing the LASSO solution</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">14. Lab 5: Coordinate descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="16-LASSO-theoretical.html">15. Theoretical guarantees for the LASSO</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-categorical-data.html">16. Analyzing categorical data</a></li>
<li class="toctree-l1"><a class="reference internal" href="18-Lab6-nearest-neighbors.html">17. Lab 6: nearest neighbors</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Content/15-Lab5-coordinate-descent.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lab 5: Coordinate descent</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-via-coordinate-descent">14.1. Linear regression via coordinate descent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-lasso-problem-using-coordinate-descent">14.2. Solving the LASSO problem using coordinate descent</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lab-5-coordinate-descent">
<h1><span class="section-number">14. </span>Lab 5: Coordinate descent<a class="headerlink" href="#lab-5-coordinate-descent" title="Link to this heading">#</a></h1>
<p>We saw previously how <a class="reference internal" href="14-Computing-lasso.html#s-coordinate-descent"><span class="std std-ref">Coordinate descent</span></a> can be used to minimize a function <span class="math notranslate nohighlight">\(f(x_1,\dots,x_p)\)</span> of several variables. Recall that the idea is to minimize the function one variable at a time, and to repeat this process over and over:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
x^{(k+1)}_1 &amp;= \mathop{\textrm{argmin}}_x f(x, x_2^{(k)}, x_3^{(k)}, \dots, x_p^{(k)}) \\
x^{(k+1)}_2 &amp;= \mathop{\textrm{argmin}}_x f(x_1^{(k+1)}, x, x_3^{(k)}, \dots, x_p^{(k)}) \\
x^{(k+1)}_3 &amp;= \mathop{\textrm{argmin}}_x f(x_1^{(k+1)}, x_2^{(k+1)}, x, x_4^{(k)}, \dots, x_p^{(k)})\\
&amp;\vdots \\
x^{(k+1)}_p &amp;= \mathop{\textrm{argmin}}_x f(x_1^{(k+1)}, x_2^{(k+1)}, \dots , x_{p-1}^{(k+1)}, x).
\end{align*}\]</div>
<p>Under certain conditions, this process converges to a local minimum of the function <span class="math notranslate nohighlight">\(f\)</span>. To illustrate how this work with Python, let us solve the linear regression problem using coordinate descent.</p>
<section id="linear-regression-via-coordinate-descent">
<h2><span class="section-number">14.1. </span>Linear regression via coordinate descent<a class="headerlink" href="#linear-regression-via-coordinate-descent" title="Link to this heading">#</a></h2>
<p>Consider the least square problem</p>
<div class="math notranslate nohighlight">
\[
\min_{\beta \in \mathbb{R}^p} \|y-X\beta\|_2^2, 
\]</div>
<p>where <span class="math notranslate nohighlight">\(y \in \mathbb{R}^n\)</span> and <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n \times p}\)</span> are fixed. In order to solve this problem via coordinate descent, we need to solve the one-variable problem</p>
<div class="math notranslate nohighlight">
\[
\min_{\beta_i \in \mathbb{R}^p} \|y-X\beta\|_2^2.
\]</div>
<p>We will do so by computing the derivative of <span class="math notranslate nohighlight">\(\|y-X\beta\|_2^2\)</span> with respect to <span class="math notranslate nohighlight">\(\beta_i\)</span> and setting it to <span class="math notranslate nohighlight">\(0\)</span>. Recall from <a class="reference internal" href="5-Linear-regression.html#sec-finding-optimal-coefficients"><span class="std std-ref">Finding the Optimal Coefficients</span></a> that</p>
<div class="math notranslate nohighlight">
\[
\nabla_\beta \|y-X\beta\|_2^2 = -2(X^Ty-X^TX \beta) = -2X^T(y-X\beta). 
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\nabla_\beta\)</span> denotes the gradient vector obtained by differentiating with respect to <span class="math notranslate nohighlight">\(\beta_1, \dots, \beta_p\)</span>. In particular, for <span class="math notranslate nohighlight">\(1 \leq i \leq p\)</span>, the <span class="math notranslate nohighlight">\(i\)</span>-th entry of the gradient is:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial}{\partial \beta_i} \|y-X\beta\|_2^2 = -2 X_i^T (y-X\beta), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(X_i\)</span> denotes the <span class="math notranslate nohighlight">\(i\)</span>-th column of <span class="math notranslate nohighlight">\(X\)</span>. Now, let <span class="math notranslate nohighlight">\(X_{-i}\)</span> denote the matrix <span class="math notranslate nohighlight">\(X\)</span> with the <span class="math notranslate nohighlight">\(i\)</span>-th column deleted, and let <span class="math notranslate nohighlight">\(\beta_{-i}\)</span> be the vector <span class="math notranslate nohighlight">\(\beta\)</span> with <span class="math notranslate nohighlight">\(i\)</span>-th entry deleted. Observe that <span class="math notranslate nohighlight">\(X\beta\)</span> = <span class="math notranslate nohighlight">\(X_{-i} \beta_{-i} + \beta_i X_i\)</span>. It follows that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\frac{\partial}{\partial \beta_i} \|y-X\beta\|_2^2 &amp;= -2 X_i^T (y-X_{-i}\beta_{-i} - \beta_i X_i) \\
&amp;= -2(X_i^T y - X_i^T X_{-i} \beta_{-i} - \beta_iX_i^T X_i).
\end{align*}\]</div>
<p>Setting the gradient to <span class="math notranslate nohighlight">\(0\)</span> and solving for <span class="math notranslate nohighlight">\(\beta_i\)</span>, we obtain:</p>
<div class="math notranslate nohighlight">
\[
\beta_i^* = \mathop{\rm argmin}_{\beta_i \in \mathbb{R}} \|y-X\beta\|_2^2 = \frac{X_i^T(y-X_{-i}\beta{-i})}{X_i^T X_i}.
\]</div>
<p>We can therefore solve the linear regression via coordinate descent as follows.</p>
<div class="admonition-linear-regression-coordinate-descent admonition">
<p class="admonition-title">Linear regression - coordinate descent</p>
<p><strong>Input</strong>: <span class="math notranslate nohighlight">\(y \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n \times p}\)</span>, initial guess <span class="math notranslate nohighlight">\(\beta^{(0)}\)</span>, tolerence <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>.</p>
<p>Set <span class="math notranslate nohighlight">\(k = 0\)</span>.</p>
<p>while <span class="math notranslate nohighlight">\(\|\left(\nabla \|y-X\beta^{(k)}\|_2^2\right)\|_2 &gt; \epsilon\)</span>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\beta^{(k+1)} = \beta^{(k)}\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(i=1,\dots,p\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\beta_i^{(k+1)} = \frac{X_i^T(y-X_{-i}\beta{-i}^{(k+1)})}{X_i^T X_i}. 
\]</div>
<ol class="arabic simple" start="3">
<li><p>Set <span class="math notranslate nohighlight">\(k = k+1\)</span>.</p></li>
</ol>
<p><strong>Output</strong>: A vector <span class="math notranslate nohighlight">\(\beta = \beta^{(k)} \in \mathbb{R}^p\)</span> such that <span class="math notranslate nohighlight">\(\|\nabla \left(\|y-X\beta\|_2^2\right)\|_2 \leq \epsilon\)</span>.</p>
</div>
<p>Let us implement this algorithm in Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the norm of the gradient function</span>

<span class="k">def</span> <span class="nf">gradnorm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span>
    <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">,</span> <span class="n">maxit</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
	<span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
	
	<span class="k">if</span> <span class="n">beta0</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># No initial guess was provided. Generate one at random.</span>
		<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">beta</span> <span class="o">=</span> <span class="n">beta0</span>
		
	<span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
	<span class="n">grad</span> <span class="o">=</span> <span class="n">gradnorm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">)</span>
	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iter </span><span class="se">\t</span><span class="s2"> Grad </span><span class="se">\t</span><span class="s2"> Err&quot;</span><span class="p">)</span>
	<span class="k">while</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">maxit</span> <span class="ow">and</span> <span class="n">grad</span> <span class="o">&gt;</span> <span class="n">epsilon</span><span class="p">:</span>
		<span class="n">beta_old</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
			<span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
			<span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="c1"># ind now contains all indices in {1,...,p} except i.</span>
			<span class="n">Xi</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span>
			<span class="n">Xmi</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">ind</span><span class="p">]</span>  <span class="c1"># All columns of X except the i-th.</span>
			<span class="n">betami</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
			<span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">Xmi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">betami</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">Xi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xi</span><span class="p">))</span>
				
		<span class="n">grad</span> <span class="o">=</span> <span class="n">gradnorm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
		<span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span> <span class="c1"># Evaluates the norm of y-X*beta</span>
		<span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> </span><span class="si">%f</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>
	<span class="k">return</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now test our code using random data and compare its solution with the solution of the problem obtained by Scikit-learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>	
<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
	<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
	<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
	<span class="n">mod</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
	<span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
	<span class="n">beta1</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">coef_</span>
	<span class="n">beta2</span> <span class="o">=</span> <span class="n">least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">maxit</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
	<span class="nb">print</span><span class="p">(</span><span class="n">beta1</span><span class="o">-</span><span class="n">beta2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iter 	 Grad 	 Err
1 	 1.392123 	 0.996686
2 	 0.923619 	 0.905546
3 	 0.615443 	 0.862639
4 	 0.412447 	 0.843040
5 	 0.278488 	 0.834176
6 	 0.189874 	 0.830153
7 	 0.131067 	 0.828304
8 	 0.091876 	 0.827437
9 	 0.065608 	 0.827020
10 	 0.047867 	 0.826811
11 	 0.035759 	 0.826703
12 	 0.027383 	 0.826643
13 	 0.021486 	 0.826609
14 	 0.017246 	 0.826588
15 	 0.014123 	 0.826574
16 	 0.011763 	 0.826565
17 	 0.009935 	 0.826559
18 	 0.008483 	 0.826555
19 	 0.007306 	 0.826552
20 	 0.006333 	 0.826549
21 	 0.005518 	 0.826547
22 	 0.004826 	 0.826546
23 	 0.004232 	 0.826545
24 	 0.003719 	 0.826544
25 	 0.003274 	 0.826543
26 	 0.002885 	 0.826543
27 	 0.002545 	 0.826543
28 	 0.002246 	 0.826542
29 	 0.001983 	 0.826542
30 	 0.001752 	 0.826542
31 	 0.001548 	 0.826542
32 	 0.001368 	 0.826542
33 	 0.001209 	 0.826542
34 	 0.001069 	 0.826541
35 	 0.000945 	 0.826541
36 	 0.000835 	 0.826541
37 	 0.000738 	 0.826541
38 	 0.000653 	 0.826541
39 	 0.000577 	 0.826541
40 	 0.000510 	 0.826541
41 	 0.000451 	 0.826541
42 	 0.000399 	 0.826541
43 	 0.000353 	 0.826541
44 	 0.000312 	 0.826541
45 	 0.000276 	 0.826541
46 	 0.000244 	 0.826541
47 	 0.000216 	 0.826541
48 	 0.000191 	 0.826541
49 	 0.000169 	 0.826541
50 	 0.000149 	 0.826541
51 	 0.000132 	 0.826541
52 	 0.000117 	 0.826541
53 	 0.000103 	 0.826541
54 	 0.000091 	 0.826541
55 	 0.000081 	 0.826541
56 	 0.000071 	 0.826541
57 	 0.000063 	 0.826541
58 	 0.000056 	 0.826541
59 	 0.000049 	 0.826541
60 	 0.000044 	 0.826541
61 	 0.000039 	 0.826541
62 	 0.000034 	 0.826541
63 	 0.000030 	 0.826541
64 	 0.000027 	 0.826541
65 	 0.000024 	 0.826541
66 	 0.000021 	 0.826541
67 	 0.000018 	 0.826541
68 	 0.000016 	 0.826541
69 	 0.000014 	 0.826541
70 	 0.000013 	 0.826541
71 	 0.000011 	 0.826541
72 	 0.000010 	 0.826541
73 	 0.000009 	 0.826541
74 	 0.000008 	 0.826541
75 	 0.000007 	 0.826541
76 	 0.000006 	 0.826541
77 	 0.000005 	 0.826541
78 	 0.000005 	 0.826541
79 	 0.000004 	 0.826541
80 	 0.000004 	 0.826541
81 	 0.000003 	 0.826541
82 	 0.000003 	 0.826541
83 	 0.000003 	 0.826541
84 	 0.000002 	 0.826541
85 	 0.000002 	 0.826541
86 	 0.000002 	 0.826541
87 	 0.000002 	 0.826541
88 	 0.000001 	 0.826541
89 	 0.000001 	 0.826541
90 	 0.000001 	 0.826541
91 	 0.000001 	 0.826541
[-7.98802829e-07 -2.04612488e-07  1.03062240e-06]
</pre></div>
</div>
</div>
</div>
<p>We obtain the same regression coefficients (up to numerical precision).</p>
</section>
<section id="solving-the-lasso-problem-using-coordinate-descent">
<h2><span class="section-number">14.2. </span>Solving the LASSO problem using coordinate descent<a class="headerlink" href="#solving-the-lasso-problem-using-coordinate-descent" title="Link to this heading">#</a></h2>
<p>Let us now consider the LASSO problem</p>
<div class="math notranslate nohighlight">
\[
\widehat{\beta}_\textrm{LASSO} = \mathop{\textrm{argmin}}_{\beta \in \mathbb{R}^p} \|y - X\beta\|_2^2 + \alpha \|\beta\|_1.
\]</div>
<p>Recall that the updated derived in <a class="reference internal" href="14-Computing-lasso.html#s-lasso-soln"><span class="std std-ref">Back to the LASSO solution</span></a> is</p>
<div class="math notranslate nohighlight">
\[
\beta_i \rightarrow \eta^S_{\lambda/\|X_i\|_2^2} \left(\frac{2 X_i^T (y-X_{-i} \beta_{-i}) }{X_i^T X_i}\right).
\]</div>
<p>This is almost the same update as in the linear regression problem.</p>
<div class="admonition-exercise admonition">
<p class="admonition-title">Exercise</p>
<p>Modify the above code to solve the LASSO problem instead of linear regression. Compare your solution with Scikit-learn and make sure the two versions match. Note that the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html" target="_blank">Lasso object of Scikit-learn</a> solves a slightly different (but equivalent) LASSO problem</p>
<div class="math notranslate nohighlight">
\[
\min_{w \in \mathbb{R}^p} \frac{1}{2n}  ||y - Xw||^2_2 + \alpha  ||w||_1.
\]</div>
<p>Observe that setting <span class="math notranslate nohighlight">\(\alpha = \frac{\lambda}{2n}\)</span> solves</p>
<div class="math notranslate nohighlight">
\[
\min_{w \in \mathbb{R}^p} \frac{1}{2n} ||y - Xw||^2_2 + \frac{\lambda}{2n}  ||w||_1 = \frac{1}{2n} \min_{w \in \mathbb{R}^p} ||y - Xw||^2_2 + \lambda  ||w||_1, 
\]</div>
<p>which is equivalent to our formulation.</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="14-Computing-lasso.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">13. </span>Computing the LASSO solution</p>
      </div>
    </a>
    <a class="right-next"
       href="16-LASSO-theoretical.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Theoretical guarantees for the LASSO</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-via-coordinate-descent">14.1. Linear regression via coordinate descent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-lasso-problem-using-coordinate-descent">14.2. Solving the LASSO problem using coordinate descent</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dominique Guillot
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>